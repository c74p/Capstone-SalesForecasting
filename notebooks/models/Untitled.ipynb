{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earlier Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>state</th>\n",
       "      <th>date</th>\n",
       "      <th>max_temperature_c</th>\n",
       "      <th>mean_temperature_c</th>\n",
       "      <th>min_temperature_c</th>\n",
       "      <th>dew_point_c</th>\n",
       "      <th>mean_dew_point_c</th>\n",
       "      <th>min_dew_point_c</th>\n",
       "      <th>max_humidity</th>\n",
       "      <th>...</th>\n",
       "      <th>promo_interval</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>sales</th>\n",
       "      <th>customers</th>\n",
       "      <th>open</th>\n",
       "      <th>promo</th>\n",
       "      <th>state_holiday</th>\n",
       "      <th>school_holiday</th>\n",
       "      <th>trend</th>\n",
       "      <th>week_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HE</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61</td>\n",
       "      <td>2012-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>HE</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>Mar,Jun,Sept,Dec</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61</td>\n",
       "      <td>2012-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69</td>\n",
       "      <td>HE</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61</td>\n",
       "      <td>2012-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>HE</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61</td>\n",
       "      <td>2012-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111</td>\n",
       "      <td>HE</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61</td>\n",
       "      <td>2012-12-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store state        date  max_temperature_c  mean_temperature_c  \\\n",
       "0      1    HE  2013-01-01                  8                   6   \n",
       "1     56    HE  2013-01-01                  8                   6   \n",
       "2     69    HE  2013-01-01                  8                   6   \n",
       "3     77    HE  2013-01-01                  8                   6   \n",
       "4    111    HE  2013-01-01                  8                   6   \n",
       "\n",
       "   min_temperature_c  dew_point_c  mean_dew_point_c  min_dew_point_c  \\\n",
       "0                  3            6                 3                1   \n",
       "1                  3            6                 3                1   \n",
       "2                  3            6                 3                1   \n",
       "3                  3            6                 3                1   \n",
       "4                  3            6                 3                1   \n",
       "\n",
       "   max_humidity     ...        promo_interval  day_of_week  sales  customers  \\\n",
       "0            93     ...                  None            1    0.0        0.0   \n",
       "1            93     ...      Mar,Jun,Sept,Dec            1    0.0        0.0   \n",
       "2            93     ...       Jan,Apr,Jul,Oct            1    0.0        0.0   \n",
       "3            93     ...       Jan,Apr,Jul,Oct            1    0.0        0.0   \n",
       "4            93     ...       Jan,Apr,Jul,Oct            1    0.0        0.0   \n",
       "\n",
       "   open  promo  state_holiday  school_holiday  trend  week_start  \n",
       "0   0.0    0.0              a             1.0     61  2012-12-30  \n",
       "1   0.0    0.0              a             1.0     61  2012-12-30  \n",
       "2   0.0    0.0              a             1.0     61  2012-12-30  \n",
       "3   0.0    0.0              a             1.0     61  2012-12-30  \n",
       "4   0.0    0.0              a             1.0     61  2012-12-30  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = Path('../../data/interim')\n",
    "df = pd.read_csv(DATA_PATH/'train_valid_data.csv', low_memory=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes[df.dtypes == 'object']\n",
    "# state, events, store_type, assortment, promo_interval, state_holiday\n",
    "# date we can skip because we'll use add_datepart() on that, and it will get turned into datetime (and many other things)\n",
    "# week_start we can delete as that will get taken into account by add_datepart() for date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Date calculations to ensure we get the correct dataframes for testing and for training/validation\n",
    "#df.date.min() # 2013-01-01\n",
    "#df.date.max() # 2015-07-31\n",
    "#pd.to_datetime('2015-07-31').dayofweek # 4 = Friday\n",
    "#pd.to_datetime('2015-07-31').week # 31\n",
    "#pd.to_datetime('2015-06-19').dayofweek # 4\n",
    "#pd.to_datetime('2015-06-19').week # 25\n",
    "#pd.to_timedelta(pd.to_datetime('2015-07-31') - pd.to_datetime('2015-06-19'))\n",
    "#test_data = df.loc[df.date >= '2015-06-20'].copy()\n",
    "#len(test_data) # 46830\n",
    "#len(test_data)/1115 # 42 days\n",
    "#train_valid_data = df.loc[df.date <= '2015-06-19'].copy()\n",
    "#len(train_valid_data) # 1003500\n",
    "#len(train_valid_data)/1115 # 900 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out how big the validation set should be\n",
    "#len(train_valid_data) # 1,003,500\n",
    "#len(train_valid_data) * .2 # 200,700\n",
    "#len(train_valid_data) * .2 / 1115 # 180 days = 20% of the train_valid_data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('../../data/interim/test_data.csv', index=False)\n",
    "print('did test')\n",
    "train_valid_data.to_csv('../../data/interim/train_valid_data.csv', index=False)\n",
    "print('did train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 1,
>>>>>>> remotes/origin/models2
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular import *\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 2,
>>>>>>> remotes/origin/models2
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../../data/interim')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/fastai/tabular/transform.py:63: RuntimeWarning: Values and categories have different dtypes. Did you mean to use\n",
      "'Categorical.from_codes(codes, categories)'?\n",
      "  df.loc[:,n] = pd.Categorical(df[n], categories=self.categories[n], ordered=True)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/fastai/tabular/transform.py:63: RuntimeWarning: None of the categories were found in values. Did you mean to use\n",
      "'Categorical.from_codes(codes, categories)'?\n",
      "  df.loc[:,n] = pd.Categorical(df[n], categories=self.categories[n], ordered=True)\n"
     ]
    },
    {
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
>>>>>>> remotes/origin/models2
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Import train_valid_data and test_data dataframes\n",
    "train_valid_df = pd.read_csv(DATA_PATH/'train_valid_data.csv', low_memory=False)\n",
    "test_df = pd.read_csv(DATA_PATH/'test_data.csv', low_memory=False)\n",
    "\n",
<<<<<<< HEAD
    "# Set up preprocessing\n",
    "# Category names, to which we'll apply embeddings\n",
    "cat_names = ['assortment', 'events', 'promo_interval', 'state', 'state_holiday', 'store_type']\n",
    "# Won't do anything with cont_names now but for completeness\n",
    "# Also note we intentionally left out week_start as that will get taken into account by add_datepart() for date\n",
=======
    "# EDIT remove these later\n",
    "#train_valid_df = train_valid_df[-64:]\n",
    "#test_df = test_df[-64:]\n",
    "\n",
    "# Category names, to which we'll apply embeddings\n",
    "cat_names = ['assortment', 'events', 'promo_interval', 'state', 'state_holiday', 'store_type']\n",
    "\n",
    "# Continuous-variable names, which we'll make sure are all represented as floats\n",
>>>>>>> remotes/origin/models2
    "cont_names = ['cloud_cover', 'competition_distance', 'competition_open_since_month', 'competition_open_since_year',\n",
    "              'customers', 'day_of_week', 'dew_point_c', 'max_gust_speed_km_h', 'max_humidity',\n",
    "              'max_sea_level_pressureh_pa', 'max_temperature_c', 'max_visibility_km', 'max_wind_speed_km_h',\n",
    "              'mean_dew_point_c', 'mean_humidity', 'mean_sea_level_pressureh_pa', 'mean_temperature_c',\n",
    "              'mean_visibility_km', 'mean_wind_speed_km_h', 'min_dew_point_c', 'min_humidity', 'min_sea_level_pressureh_pa',\n",
    "              'min_temperature_c', 'min_visibility_km', 'open', 'precipitationmm', 'promo', 'promo2', 'promo2_since_week',\n",
    "              'promo2_since_year', 'school_holiday', 'store', 'trend', 'wind_dir_degrees']\n",
    "\n",
<<<<<<< HEAD
=======
    "# Make sure continuous categories are represented as floats\n",
    "train_valid_df[cont_names] = train_valid_df[cont_names].astype('float')\n",
    "test_df[cont_names] = test_df[cont_names].astype('float')\n",
    "\n",
    "# Make sure categories are represented as strings\n",
    "train_valid_df[cat_names] = train_valid_df[cat_names].astype('object')\n",
    "test_df[cat_names] = test_df[cat_names].astype('object')\n",
    "\n",
    "# Make sure continuous categories are represented as floats\n",
    "train_valid_df['sales'] = train_valid_df['sales'].astype('float')\n",
    "test_df['sales'] = test_df['sales'].astype('float')\n",
    "\n",
    "# Drop week_start as that will get taken into account by add_datepart() for date\n",
    "train_valid_df.drop('week_start', axis='columns', inplace=True)\n",
    "test_df.drop('week_start', axis='columns', inplace=True)\n",
    "\n",
>>>>>>> remotes/origin/models2
    "# We can define a bunch of Transforms that will be applied to our variables. \n",
    "# Here we transform all categorical variables into categories. \n",
    "# We also replace missing values for continuous variables by the median column value and normalize those.\n",
    "# And we add columns relevant to the date: ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end',\n",
    "#                             'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "# Note that FillMissing should do nothing since we don't have any NaNs -- leaving it in anyway\n",
    "procs = [FillMissing, Categorify, Normalize]#,\n",
<<<<<<< HEAD
    "         #add_datepart(train_valid_df, 'date', drop=True, time=False)]#,\n",
    "         #add_datepart(test_df, 'date', drop=True, time=False)]\n",
    "\n",
    "valid_idx = range(len(df)-200700, len(df))\n",
    "data = TabularDataBunch.from_df(path=DATA_PATH, df=df, test_df=test_df, dep_var='sales', valid_idx=valid_idx,\n",
    "                                     procs=procs, cat_names=cat_names, cont_names=cont_names, bs=64, num_workers=4)\n",
=======
    "         #[add_datepart(train_valid_df, 'date', drop=True, time=False),\n",
    "         #add_datepart(train_valid_df, 'date', drop=True, time=False)]#,\n",
    "         #add_datepart(test_df, 'date', drop=True, time=False)]\n",
    "\n",
    "df = train_valid_df\n",
    "# EDIT Remove these notes later\n",
    "# To change this back to a real thing:\n",
    "# 1) change valid_idx as below\n",
    "# 2) change bs back to 64\n",
    "# 3) change 'layers' down in the call to 'learn' a couple cells down\n",
    "#valid_idx = range(len(df)-20, len(df))\n",
    "valid_idx = range(len(df)-200700, len(df))\n",
    "data = TabularDataBunch.from_df(path=DATA_PATH, df=df, test_df=test_df, dep_var='sales', valid_idx=valid_idx,\n",
    "                                     procs=procs, cat_names=cat_names, cont_names=cont_names, bs=64, num_workers=4)\n",
    "                                     #procs=procs, cat_names=cat_names, cont_names=cont_names, bs=2, num_workers=4)\n",
>>>>>>> remotes/origin/models2
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 82,
=======
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_df.info()\n",
    "mcats = cont_cat_split(test_df, max_card = 200)[1]\n",
    "len(mcats) # 24\n",
    "sorted(mcats) # ['assortment', 'date', 'events', 'promo_interval', 'state', 'state_holiday', 'store_type']\n",
    "sorted(cat_names) # ['assortment', 'events', 'promo_interval', 'state', 'state_holiday', 'store_type']\n",
    "#test_df[cont_names] = test_df[cont_names].astype('float')\n",
    "#test_df[cont_names].dtypes\n",
    "#test_df[cat_names].dtypes\n",
    "#test_df['sales'].dtype\n",
    "#'sales' in cont_names # False\n",
    "#'sales' in cat_names # False\n",
    "#test_df[cat_names].info()\n",
    "#train_valid_df.state_holiday.unique()\n",
    "test_df.state_holiday.dtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
>>>>>>> remotes/origin/models2
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[[  1 510   1   4   7   1   1]\n",
      " [  1 344  11   2   2   1   4]\n",
      " [  3 651   2   1   2   1   4]\n",
      " [  1  88  15   4   1   3   1]\n",
      " [  1 745  12   2   8   1   1]]\n",
      "[[-1.544212 -0.437269  1.446941 -0.924744 ... -0.447853  1.656357 -0.97199   0.986241]\n",
      " [ 0.380457 -0.508535  0.006039 -0.026026 ... -0.447853 -0.860089  0.639254 -1.002204]\n",
      " [ 1.022013  0.613243  0.006039 -0.026026 ... -0.447853  0.231196 -0.213757  0.922441]\n",
      " [ 1.022013 -0.589039 -1.224722  0.807686 ...  2.232873 -1.379453  0.165359  1.847547]\n",
      " [ 0.380457 -0.672182  1.828606 -0.732252 ... -0.447853 -1.685508  0.354917  0.13557 ]]\n",
      "[   0. 4228.    0.    0. 7481.]\n"
=======
      "[[ 3 20  4  1  1  4]\n",
      " [ 3 22  4  3  1  3]\n",
      " [ 1 12  2  5  1  1]\n",
      " [ 3 12  2  8  1  1]\n",
      " [ 3  2  2  2  1  1]]\n",
      "[[ 0.380457 -0.528331  1.446941  1.000178 ... -0.447853 -0.019212 -0.403315 -1.42754 ]\n",
      " [ 0.380457 -0.040027  0.006039 -0.026026 ... -0.447853 -1.52166  -0.97199  -0.980937]\n",
      " [-0.2611   -0.604876  1.065274  1.000178 ... -0.447853  0.68564  -1.351106  0.826741]\n",
      " [ 1.022013 -0.303975 -0.46139  -0.347267 ... -0.447853 -1.555666  0.165359 -1.119171]\n",
      " [ 0.380457 -0.528331 -0.843055  0.807686 ... -0.447853 -0.925009 -1.351106  1.432844]]\n",
      "[6923. 5203. 6400. 8708. 3396.]\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.float32\n"
>>>>>>> remotes/origin/models2
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "data = testorama\n",
    "(cat_x,cont_x),y = next(iter(data.train_dl))\n",
    "for o in (cat_x, cont_x, y): print(to_np(o[:5]))"
=======
    "(cat_x,cont_x),y = next(iter(data.train_dl))\n",
    "for o in (cat_x, cont_x, y): print(to_np(o[:5]))\n",
    "for o in (cat_x, cont_x, y): print(o.dtype)"
>>>>>>> remotes/origin/models2
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 93,
=======
   "execution_count": 6,
>>>>>>> remotes/origin/models2
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
<<<<<<< HEAD
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
=======
       "Total time: 06:51 <p><table style='width:300px; margin-bottom:10px'>\n",
>>>>>>> remotes/origin/models2
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
<<<<<<< HEAD
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='3136', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
=======
       "    <th>root_mean_squared_error</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>6813576.000000</th>\n",
       "    <th>5890387.500000</th>\n",
       "    <th>2337.806641</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>2242702.250000</th>\n",
       "    <th>1443379.250000</th>\n",
       "    <th>1101.291992</th>\n",
       "  </tr>\n",
       "</table>\n"
>>>>>>> remotes/origin/models2
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
<<<<<<< HEAD
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Float for argument #2 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-1a2b5d31c70d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtabular_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_szs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memb_szs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start, tot_epochs=tot_epochs, \n\u001b[1;32m     21\u001b[0m                                        start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\n\u001b[0;32m--> 178\u001b[0;31m             callbacks=self.callbacks+callbacks)\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/utils/mem.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             if (\"CUDA out of memory\" in str(e) or\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, data, callbacks, metrics)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 val_loss = validate(model, data.valid_dl, loss_func=loss_func,\n\u001b[0;32m---> 95\u001b[0;31m                                        cb_handler=cb_handler, pbar=pbar)\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dl, loss_func, cb_handler, pbar, average, n_batch)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mnums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_batch\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;34m\"Handle end of processing one batch with `loss`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch_end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iteration'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, cb_name, call_mets, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_mets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;34m\"Call through to all of the `CallbakHandler` functions.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcall_mets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'on_{cb_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'on_{cb_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_mets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;34m\"Call through to all of the `CallbakHandler` functions.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcall_mets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'on_{cb_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'on_{cb_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, last_output, last_target, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlast_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_target\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlast_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlast_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlast_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/metrics.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(input, targs)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maccuracy_thresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mRank0Tensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #2 'other'"
     ]
=======
>>>>>>> remotes/origin/models2
    }
   ],
   "source": [
    "emb_szs = {'assortment': 2, 'events': 11, 'promo_interval': 2, 'state': 6, 'state_holiday': 2, 'store_type': 2} \n",
    "\n",
<<<<<<< HEAD
    "learn = tabular_learner(data, layers=[200,100], emb_szs=emb_szs, metrics=accuracy)\n",
    "learn.fit_one_cycle(1, 1e-2)"
=======
    "def rmspe(pred, true):\n",
    "    # Remove elements where true == 0, to avoid div/0 errors\n",
    "    pred = pred[true != 0]\n",
    "    true = true[true != 0]\n",
    "    # Return means of percentage errors\n",
    "    return (((true - pred)/true)**2).mean()\n",
    "\n",
    "#learn = tabular_learner(data, layers=[200,100], emb_szs=emb_szs, metrics=accuracy)\n",
    "#learn = tabular_learner(data, layers=[1], emb_szs=emb_szs, metrics=accuracy)\n",
    "#learn = tabular_learner(data, layers=[1], emb_szs=emb_szs, metrics=None)#accuracy)\n",
    "learn = tabular_learner(data, layers=[1], emb_szs=emb_szs, metrics=rmse)\n",
    "learn.fit_one_cycle(cyc_len=2, max_lr=1e-2)"
>>>>>>> remotes/origin/models2
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict(df.iloc[0])"
=======
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store                                        803\n",
       "state                                         HE\n",
       "date                                  2013-04-04\n",
       "max_temperature_c                             10\n",
       "mean_temperature_c                             6\n",
       "min_temperature_c                              1\n",
       "dew_point_c                                   -2\n",
       "mean_dew_point_c                              -4\n",
       "min_dew_point_c                               -6\n",
       "max_humidity                                  70\n",
       "mean_humidity                                 52\n",
       "min_humidity                                  28\n",
       "max_sea_level_pressureh_pa                  1014\n",
       "mean_sea_level_pressureh_pa                 1010\n",
       "min_sea_level_pressureh_pa                  1008\n",
       "max_visibility_km                             18\n",
       "mean_visibility_km                            12\n",
       "min_visibility_km                             10\n",
       "max_wind_speed_km_h                           32\n",
       "mean_wind_speed_km_h                          16\n",
       "max_gust_speed_km_h                      48.8643\n",
       "precipitationmm                                0\n",
       "cloud_cover                                    7\n",
       "events                                 No Events\n",
       "wind_dir_degrees                              53\n",
       "store_type                                     d\n",
       "assortment                                     a\n",
       "competition_distance                        1760\n",
       "competition_open_since_month              7.2247\n",
       "competition_open_since_year              2008.67\n",
       "promo2                                         1\n",
       "promo2_since_week                             10\n",
       "promo2_since_year                           2014\n",
       "promo_interval                  Mar,Jun,Sept,Dec\n",
       "day_of_week                                    3\n",
       "sales                                       5614\n",
       "customers                                    494\n",
       "open                                           1\n",
       "promo                                          0\n",
       "state_holiday                                  0\n",
       "school_holiday                                 1\n",
       "trend                                         61\n",
       "Name: 10500, dtype: object"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learn.predict(df.iloc[24]) # (FloatItem [-0.716882], tensor([-0.7169]), tensor([-0.7169]))\n",
    "#df[df.sales != 0]\n",
    "# df.iloc[24] #sales = 4920\n",
    "#df.sales.mean() # 8262\n",
    "#len(df) #64\n",
    "#learn.data.classes\n",
    "#learn.get_preds()[0] # tensor([[-0.5554], [-0.4584], [-0.5775], [-0.5595], [-0.5216], [-0.5999], [-0.6018], [-0.5896], [-0.5815], [-0.6059], [-0.7594], [-0.5893], [-0.5686], [-0.6069], [-0.6009], [-0.6230], [-0.5981], [-0.5996], [-0.6550], [-0.4852]])\n",
    "#learn.get_preds()[1] #tensor([ 9724.,  9676., 11135., 11038., 11745.,  5417.,  5386.,  5728.,  5100., 3659.,  6280.,  7113., 11077.,  4360.,  7211.,  7605.,  6168.,  9517., 5025., 21834.])\n",
    "#df[-20:].sales.values # array([ 9724.,  9676., 11135., 11038., 11745.,  5417.,  5386.,  5728.,  5100.,  3659.,  6280.,  7113., 11077.,  4360., 7211.,  7605.,  6168.,  9517.,  5025., 21834.])\n",
    "#a = learn.get_preds()\n",
    "df.iloc[10500] # sales = 5614\n",
    "learn.predict(df.iloc[10500]) # (FloatItem [2197.8691], tensor([2197.8691]), tensor([2197.8691]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FloatItem [4658.547], tensor([4658.5469]), tensor([4658.5469]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is it learning?  This is the output from a 2-epoch run. It's better than the output from a single-epoch run.\n",
    "df.iloc[10500] # sales = 5614\n",
    "learn.predict(df.iloc[10500]) # (FloatItem [4658.547], tensor([4658.5469]), tensor([4658.5469]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-a9ae03b52a9e>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-a9ae03b52a9e>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    python -c 'import fastai.utils.collect_env; fastai.utils.collect_env.show_install(1)'\u001b[0m\n\u001b[0m                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch; print(torch.cuda.is_available())"
>>>>>>> remotes/origin/models2
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
